\documentclass[a4paper,11pt]{article} %, landscape report

\usepackage[T1]{fontenc}
\usepackage[utf8x]{inputenc}

%Selon les goûts: times palatino bookman newcent chancery helvet avant fourier kpfonts cmbright
%\usepackage{avant}

%\usepackage[hmargin=2cm,vmargin=2cm]{geometry}
%\usepackage{multicol}
%\setlength{\columnsep}{1cm}
\usepackage{ragged2e}% for \justifiy

\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{multicol}\setlength{\columnsep}{1cm}

\usepackage{amsmath,amssymb,amsfonts,makeidx}
\usepackage{stmaryrd}% crochets «intervalles d'entiers»
%\newcommand{\B}{\mathbb{B}}
\usepackage{tikz}
\newcommand{\e}{\text{e}}

\usepackage{lscape}

\newcommand{\vesp}{\vspace*{0.2em}}
\newcommand{\VESP}{\vspace*{0.8em}}
\newcommand{\ttt}[1]{\texttt{#1}}
\newcommand{\file}[1]{\colorbox{blue!10}{\texttt{#1}}}
\newcommand{\code}[1]{\textcolor{blue}{\texttt{#1}}}
\newcommand{\rem}[1]{\colorbox{yellow}{\textbf{#1}}}
\newcommand{\REM}[1]{\colorbox{yellow}{\color{red}\textbf{#1}}}
\newcommand{\evid}[1]{\colorbox{blue!10}{\textbf{#1}}}

\newcommand{\prop}[1]{\begin{center}\rule{0.95\linewidth}{0.5pt}\\\textsf{#1}\\\rule{0.95\linewidth}{0.5pt}\end{center}}

\usepackage{hyperref}
\hypersetup{colorlinks=true,
            linkcolor=violet,
            urlcolor=teal,
            citecolor=olive,
            }
\newcommand{\www}[2]{\href{#1}{\nolinkurl{#2}}}
%black, blue, brown, cyan, darkgray, gray, green, lightgray, lime, magenta, olive, orange, pink, purple, red, teal, violet, white, yellow
%\urlstyle{same}% Pas stylés \og URL

%\usepackage[nosort]{cite}

\usepackage{minted}
\usemintedstyle{%friendly, %colorful, %autumn
    breaklines, fontfamily=courier,%helvetica,%tt,
    bgcolor=gray!10,
    %framesep=2mm,
    %fontsize=\large,
    %frame=lines,%single,
    numbers=none,%left,
    autogobble, mathescape, texcomments,
    %stepnumber=2,
    escapeinside=\%
}
% Inline
\newcommand{\Py}[1]{\mintinline[bgcolor=gray!15]{python}{#1}}
\newcommand{\BPy}[1]{\textbf{\Py{#1}}}
\newcommand{\SerreCode}{\vspace*{-0.8em}}
%\newcommand{\Py}[1]{\colorbox{gray!20}{\texttt{#1}}}


%\newcommand{\1}{\textcircled{\small 1}}
%\newcommand{\2}{\textcircled{\small 2}}
\setlength{\parskip}{0.2em}
%\setlength{\parindent}{0ex}

\usepackage[french]{babel} \frenchbsetup{StandardLists=true}
\usepackage[autolanguage]{numprint}
\DecimalMathComma

\AddThinSpaceBeforeFootnotes
\FrenchFootnotes

% =================================================================================================
\title{\textbf{Implémentation de la DP dans pytorch-dp\\{\small Exemple avec le MNIST}}}
\author{}
\date{}

\begin{document}%\setlength\parindent{5mm}
\maketitle
\tableofcontents
%%
\section{Étude de l'exemple du MNIST}
%%
%
\subsection{Organisation générale}
%
On omet volontairement certains détails, d'autant que le projet, très actif, est régulièrement modifié (\emph{ce fût le cas notamment pour la structure même du modèle de cet exemple, durant son étude de notre part}).
\\\rem{. Rappeler ici le principe du SGM ?}

Le script \file{examples/mnist.py} est exécutable directement en ligne de commande (sa fonction \code{main()} est alors appelée). Le réseau neuronal convolutif est modélisé par la classe \code{SampleConvNet} qui hérite de \code{nn.Module}.

Le répertoire \file{torchdp/} fournit les outils assurant le respect de la confidentialité différentielle ainsi que sa gestion. Ils interviennent ici à deux endroits: dans \code{main()} pour rendre le modèle conforme à cette exigence, puis dans la méthode \code{train()} de \code{SampleConvNet}, qui traite la phase d'apprentissage, en affichant au fur et à mesure notamment la consommation du \og budget de confidentialité\fg{}.
%
\subsection{Transformation du modèle en version DP}
%
\subsubsection{Utilisation habituelle de \ttt{pytorch}}
%
Rappelons d'abord le déroulement de l'entraînement d'un modèle classique, ici d'apprentissage supervisé d'un réseau neuronal convolutif visant à catégoriser des images.\REM{Principes généraux d'un CNN à voir avant...}

On peut instancier un objet \code{model} d'une classe héritant de \code{nn.Module} (on désigne généralement \code{torch.nn} par l'alias \code{nn}) pour décrire la structure du modèle. Le constructeur définit les différentes couches qui le constituent.%
    \begin{minted}{python3}
    def __init__(self):
        super(MyNet, self).__init__()
        self.conv1 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16*5*5, 120) # ...
    \end{minted}
La méthode \code{forward()} sera appliquée comme son nom l'indique lors de la phase de propagation directe, de calcul des sorties à partir de données d'entraînement, à comparer avec les valeurs attendues associées, toutes deux issues du \emph{training dataset}. On indique donc dans sa définition les différentes couches du modèle, les fonctions d'activation et autres réorganisations \og géométriques\fg{} des tenseurs, avant de renvoyer le résultat de cette séquence de transformations.
    \begin{minted}{python3}
    # import torch.nn.functional as F
    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.max_pool2d(x, 2, 2)
        x = F.relu(self.fc1(x)) # ...
        return x
    \end{minted}

On précise une fonction de coût (\emph{loss function}) pour quantifier l'erreur entre les sorties et les valeurs attendues. Un objet \code{optimizer} est créé~--- les principaux étant disponibles \og clé en main\fg{} dans le module \ttt{torch.optim}~--- qui gèrera l'optimisation et les calculs de gradients associés grâce à sa méthode \code{step()}.
    \begin{minted}{python3}
    # import torch.optim as optim
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(params, lr=0.1, momentum=0.0)
    \end{minted}

Reste alors à itérer la phase d'entraînement: remise à zéro des gradients, calcul des sorties avec les paramètres en cours puis du coût associé, rétropropagation du gradient pour mettre à jour les paramètres (et suivi des performances).
    \begin{minted}{python3}
    # `trainloader` contient le training set
    losses = []
    for inputs, labels in trainloader:
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(ouputs, labels)
        loss.backward()    # Thanks to PyTorch,
        optimizer.step()   #  everthing is 'automatic' !
        losses.append(loss.item())
        # if ... : print(np.mean(losses))
    \end{minted}

On peut construire une phase de test de manière analogue, tout en évitant les calculs de gradients, donc sans utilisation de l'\code{optimizer}.
    \begin{minted}{python3}
    with torch.no_grad():
        for inputs, labels in testloader:
            outputs = model(inputs)
            loss += criterion(ouputs, labels).item()
            # Index of the max log-probability
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(label.view_as(pred)).sum().item()
    loss /= len(test_loader.dataset)
    \end{minted}

Analysons maintenant ce qui diffère, dans la version adaptée à la confidentialité différentielle.
%
\subsubsection{Adaptation en version DP}
\rem{... TODO ...}

Mais au final, pour pouvoir mettre concrètement en œuvre ces mécanismes, il faut savoir calibrer le bruit ajouté par le SGM, l'ajuster aux paramètres de DP qu'on s'est accordés. Cela dépendra également de la structure du réseau neuronal, ainsi que du nombre d'itérations en phase d'entraînement. Étudions la partie consacrée à ces calculs.
%
\subsection{Comptabilité de la confidentialité: contenu de \ttt{torchdp/}}
%
\subsubsection{\ttt{privacy\_engine.py}}
%
On y définit une classe \code{PrivacyEngine}, construite notamment à partir d'une instance \code{model} de \code{SampleConvNet}, des hyper-paramètres (\code{batch\_size}, \code{noise\_multiplier} égal au \ttt{sigma} passé en argument, \code{max\_grad\_norm}...) et de la liste des moments \code{alphas} qui seront utilisés pour estimer de manière optimale, grâce à la Rényi-DP, la consommation $\varepsilon$ du budget de confidentialité lors de la phase d'entraînement.

\begin{itemize}
    \item 
     Cette classe se chargera d'\textbf{adapter l'objet \code{model}, afin de le rendre} garant de la confidentialité différentielle (on le dira \textbf{DP}, pour \emph{Differentialy Private}). Ceci est assuré en définissant une méthode \code{step()} spécifique, visant à remplacer son homonyme standard. Puis une autre \code{attach()} qui transforme à chaud (\og \emph{monkey patch}\fg{}) l'\emph{optimizer} non privatif choisi pour l'entraînement, en y substituant la version modifiée de \code{step()} afin de le rendre DP.
    %
    \item 
    On y trouve également la méthode \code{get\_privacy\_spent()} ---~appelée par \code{train()} de notre exemple \file{mnist.py}~--- qui renvoie les valeurs $(\varepsilon,\,\alpha)$ indiquant le budget $\varepsilon$ consommé  pour chaque \emph{epoch} et l'ordre du moment optimal associé (ce $\alpha$ étant celui de la Rényi-DP utilisée pour les calculs), à partir de la valeur de $\delta$ qu'on s'est autorisée en termes de $(\varepsilon,\,\delta)$-DP.\\
    Elle-même utilise la méthode \code{get\_renyi\_divergence(self)} qui lui renvoie le coût en termes de Rényi-DP-$\varepsilon$ pour une occurence du \emph{Sampled Gaussian Mechanism}. Toutes deux présentent des interfaces pratiques, mais le cœur des calculs est déporté dans des fonctions du module \code{tf\_privacy}, alias du fichier suivant.
\end{itemize}
%
\subsubsection{\ttt{privacy\_analysis.py}}
%
C'est en effet le moteur des calculs de DP, qui exploite les résultats théoriques récents. C'est une reprise, quasiment à l'identique, des outils de calculs du projet \textbf{TensorFlow Privacy} de Google. Il expose deux fonctions:

\begin{itemize}
    \item 
    \code{get\_privacy\_spent(orders, rdp, delta)} renvoie le couple de valeurs Rényi-DP $(\varepsilon,\,\alpha)$ optimal: elle détermine celui pour lequel le $\varepsilon'$ qu'on peut en déduire en termes de $(\varepsilon',\,\delta)$-DP est minimal, parmi les valeurs de $\alpha$ envisagées et passées par la liste \code{orders} et celles associées de $\varepsilon$ données dans \code{rdp}.\\
    La \textbf{justification} du calcul associé à chaque couple $(\varepsilon',\,\alpha)$ est donnée par la propriété suivante\footnote{\textsf{Proposition 3} dans \og Rényi Differential Privacy\fg{}, Ilya Mironov, août $2\,017$ [arXiv:1702.07476] qu'on notera \textbf{\ttt{[MIR17]}} dans la suite} qui permet de déterminer la \og courbe de budget\fg{}, à savoir les couples $(\varepsilon,\,\alpha)$ pour la Rényi-DP :
    \prop{Pour tout $0<\delta<1$,\\
        si un mécanisme aléatoire est $(\varepsilon,\,\alpha)$-Rényi DP,\\
        alors il est également $(\varepsilon',\, \delta)$-DP pour $\varepsilon'=\varepsilon+\frac{\ln 1/\delta}{\alpha-1}$.}
    %
    \item 
    \code{compute\_rdp(q, noise\_multiplier, steps, orders)} fournit justement les valeurs de $\varepsilon$ (ici \code{rdp}), en fonction des ordres des moments $\alpha$ envisagés indiqués par \code{orders}, du taux d'échantillonnage \code{q} (\emph{détailler, lot / batch, ici ? en note de bas de page ?}), de l'écart-type \code{noise\_multiplier} du bruit gaussien ajouté et du nombre \code{steps} de répétitions. Le calcul est en réalité sous-traité par la fonction \og privée\fg{} \code{\_compute\_rdp()}.
\end{itemize}
\code{\_compute\_rdp(q, sigma, alpha)} renvoie le coût $\varepsilon$ de la RDP à l'ordre \code{alpha} du mécanisme gaussien (SGM, \emph{Sampled Gaussian Mechanism}) de taux d'échantillonnage \code{q} et d'écart-type \code{sigma}.

Le calcul est direct dans le cas où \code{q} vaut \code{1.0}, grâce à la propriété suivante\footnote{\textsf{Proposition 7} \& \textsf{Corollary 3}, dans \textbf{\ttt{[MIR17]}}.}~--- qui montre une \og courbe de budget RDP\fg{} qui est une droite passant par l'origine puisque $\varepsilon = \frac{1}{2\sigma^2}\alpha$ :
\prop{Si une fonction $f$ a une sensibilité de 1,\\
      alors le SGM d'écart-type $\sigma$ appliqué à $f$ est\\
      $(\alpha,\, \alpha/(2\sigma^2))$-Rényi DP pour tout $\alpha>1$.}

Quand \code{0 < q < 1}, \code{\_compute\_log\_a(q, sigma, alpha)} renvoie une valeur $\ln(A_\alpha)$ calculée en fonction de $\alpha>1$, telle que\footnote{***ref. erreur inégalité def Aalpha*****}:
\prop{
    Si $f$ a une sensibilité de $1$\quad et\quad si $\varepsilon \geqslant \frac{\ln (A_\alpha)}{\alpha - 1}$,\\
    alors le SGM appliqué à $f$ (avec les paramètres \code{q}, \code{sigma}) est $(\alpha,\, \varepsilon)$-RDP.
    }
En pratique \code{\_compute\_rdp()} choisit bien sûr la valeur $\varepsilon = \frac{\ln (A_\alpha)}{\alpha - 1}$, pour minimiser le budget consommé. 

Le calcul de $\ln(A_\alpha)$ est traité différemment\footnote{\emph{cf.} \textbf{\texttt{[MIR19]}}, partie \textsf{3.3}.} selon que $\alpha$ est entier (calcul direct assuré par \code{\_compute\_log\_a\_int()}) ou non (approximation par une série convergente via \code{\_compute\_log\_a\_frac()}).

\REM{Pour l'instant, j'ai un souci avec la sensibilité 1 !}\\
En effet, cela ne me semble pas garanti dans l'algo. 1 du \og Abadi $2\,016$\fg{} utilisé dans pytorch-dp, si le seuil de clipping du gradient est supérieur à 1...\vspace{-0.4em}

\begin{itemize}
    \item 
    pour $q=1$: pour une fonction $f$ de sensibilité $S_f$, le SGM sur $f$ d'écart-type $S_f \sigma$ est $(\varepsilon,\, \delta)$-DP si $\varepsilon<1$ et $\delta>\frac{4}{5}\exp(-\sigma^2\varepsilon^2/2)$ , \emph{cf.} Dwork Roth \og Algorithmic Fundation of DP\fg{} en $2\,014$ ou $2\,013$), mais on parle alors de DP classique, pas de RDP. Or c'est bien la RDP qui justifie nos calculs \og serrés\fg{} ici...
    \item 
    Pour l'autre cas avec $A_\alpha$: je n'ai pas totalement saisi comment Mironov déduit (dans [MIR17]) coroll. 3 de de la prop. 7. Si l'idée que je devine vaguement est correcte (je me fie à ce qu'il fait juste avant au coroll. 2 pour Laplace, \og since the Laplace mecanism is additive...\fg{}), on devrait pouvoir passer de la Prop. 7 avec un $\mu$ égal à la sensibilité de $f$ à la RDP pour $\varepsilon = \alpha / (2\mu^2\sigma^2)$, dans une sorte de Coroll. 3bis... À approfondir!
\end{itemize}
\REM{Fin de la parenthèse...}\\



\end{document}